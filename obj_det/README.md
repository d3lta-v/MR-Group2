# How to run

## Context

Objectives for this assignment:

The score for this section will be split into 2 parts.
1. Arriving at the specified goal position (within 30cm) [20 points].
2. Detecting the position of the objects (within 30cm) and give the correct label of the objects. Each correctly labeled and positioned object is 20 points. There will be 3 objects. We will check your csv file on the spot to score. Thus, make sure that the csv file is automatically generated by your algorithm.

## Pre-installation

Confirm that these settings must be set correctly on `common.yaml` (for a full example of the config file, see [here](https://github.com/stereolabs/zed-ros-wrapper/blob/master/zed_wrapper/params/common.yaml)):

```yaml
object_detection:
    od_enabled:                         true                    # True to enable Object Detection
    model:                              'MULTI_CLASS_BOX_FAST'  # Only use the FAST model, anything else is too taxing for the Jetson
    max_range:                          5.                      # Maximum detection range. Lower the detection range as our area of ops is 2.5m
    allow_reduced_precision_inference:  true                    # Allow inference to run at a lower precision to improve runtime and memory usage
    prediction_timeout:                 0.5                     #  During this time [sec], the object will have OK state even if it is not detected. Set this parameter to 0 to disable SDK predictions            
    object_tracking_enabled:            true                    # This MUST be enabled to ensure ZED SDK retains custody of the object 
                                                                # even when it goes out of frame
    mc_people:                          true                    # Enable for our project
    mc_vehicle:                         true                    # Enable for our project
    mc_bag:                             false
    mc_animal:                          false
    mc_electronics:                     false
    mc_fruit_vegetable:                 false
    mc_sport:                           false
```

## Installation

Place the folder inside your ROS workspace's src folder, and then build it with 

```
cd ~/ros2_ws
colcon build --packages-select obj_det --symlink-install
```

## Running

1. In the first terminal, run `ros2 launch zed_wrapper zed_camera.launch.py camera_model:=zed2` to start the camera
2. In the second terminal, run `remote_control` to enable the car's remote control system. Press the reset button on the Arduino once
3. In the third terminal, run the car control script `ros2 launch car_control car_control.launch.py`
4. Finally, launch our custom script `ros2 run obj_det obj_visualizer`
5. Place the car in autonomous mode by pressing the O button on the controller

Additionally, consider running rtabmap with the following command

```bash
ros2 launch zed_wrapper rtabmap.launch.py \
    localization:=true \
    rgb_topic:=/zed/zed_node/rgb/image_rect_color \
    depth_topic:=/zed/zed_node/depth/depth_registered \
    camera_info_topic:=/zed/zed_node/rgb/camera_info \
    odom_topic:=/zed/zed_node/odom \
    visual_odometry:=true \
    frame_id:=zed_camera_link \
    approx_sync:=true \
    wait_imu_to_init:=true \
    rgbd_sync:=true \
    approx_rgbd_sync:=true \
    imu_topic:=/zed/zed_node/imu/data \
    qos:=0 \
    rviz:=true \
    rtabmapviz:=false \
    database_path:="/home/nvidia/saved_db" \
    initial_pose:="0 0 0 0 0 0"
```
